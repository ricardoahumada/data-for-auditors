{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An√°lisis y Limpieza de Datos\n",
    "\n",
    "## Contexto del Dataset\n",
    "- **Fuente**: Tabla `sales` de base de datos PostgreSQL empresarial\n",
    "- **Prop√≥sito**: An√°lisis de ventas de productos y gesti√≥n de pedidos\n",
    "- **Per√≠odo temporal**: Datos hist√≥ricos de ventas para an√°lisis de rendimiento\n",
    "- **Objetivo**: Limpiar y preparar datos para an√°lisis posterior\n",
    "\n",
    "## Objetivos de Limpieza\n",
    "1. Identificar y documentar problemas de calidad de datos\n",
    "2. Limpiar outliers y valores inconsistentes\n",
    "3. Validar reglas de negocio espec√≠ficas del dominio\n",
    "4. Generar reporte de m√©tricas de calidad\n",
    "5. Preparar dataset final para an√°lisis\n",
    "\n",
    "## Columnas del Dataset\n",
    "- `ordernumber`: N√∫mero de orden √∫nico\n",
    "- `orderdate`: Fecha de la orden\n",
    "- `quantityordered`: Cantidad de productos ordenados\n",
    "- `priceeach`: Precio por unidad\n",
    "- `sales_amount`: Monto total de la venta\n",
    "- `status`: Estado del pedido\n",
    "- `productcode`: C√≥digo del producto\n",
    "- `customerid`: ID del cliente\n",
    "- `comments`: Comentarios adicionales\n",
    "- `shippeddate`: Fecha de env√≠o\n",
    "- `requireddate`: Fecha requerida de entrega"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar librer√≠as necesarias\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import psycopg2\n",
    "from sqlalchemy import create_engine, text\n",
    "import json\n",
    "import os\n",
    "from datetime import datetime\n",
    "from IPython.display import display\n",
    "\n",
    "# Configuraci√≥n de visualizaci√≥n\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 10\n",
    "\n",
    "print(\"Librer√≠as importadas correctamente!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "# Suprimir solo UserWarning y FutureWarning\n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. CARGA DE DATOS Y CONFIGURACI√ìN\n",
    "\n",
    "### Configuraci√≥n de Conexi√≥n\n",
    "> Actualizar las credenciales seg√∫n tu entorno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuraci√≥n de conexi√≥n a PostgreSQL\n",
    "# IMPORTANTE: Reemplazar con tus credenciales reales\n",
    "conn_string = 'postgresql+psycopg2://usuario:contrase√±a@localhost:5432/nombre_basedatos'\n",
    "engine = create_engine(conn_string)\n",
    "\n",
    "# Consulta SQL para traer los datos\n",
    "query = \"SELECT * FROM sales;\"\n",
    "\n",
    "# Cargar los datos en un DataFrame\n",
    "try:\n",
    "    df = pd.read_sql(query, engine)\n",
    "    print(f\"Datos cargados exitosamente: {df.shape[0]:,} filas x {df.shape[1]} columnas\")\n",
    "    print(f\"Memoria utilizada: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "except Exception as e:\n",
    "    print(f\"Error al cargar datos: {e}\")\n",
    "    print(\"Verifica la conexi√≥n y credenciales de la base de datos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîç 2. AN√ÅLISIS EXPLORATORIO INICIAL\n",
    "\n",
    "### Resumen General del Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AN√ÅLISIS EXPLORATORIO PRELIMINAR\n",
    "print(\"=\" * 50)\n",
    "print(\"RESUMEN DEL DATASET\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Dimensiones: {df.shape[0]:,} filas x {df.shape[1]} columnas\")\n",
    "print(f\"Memoria utilizada: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "print(f\"Per√≠odo de datos: {df['orderdate'].min()} a {df['orderdate'].max()}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"PRIMERAS 5 FILAS\")\n",
    "print(\"=\" * 50)\n",
    "display(df.head())\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"INFORMACI√ìN GENERAL\")\n",
    "print(\"=\" * 50)\n",
    "df.info()\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"ESTAD√çSTICAS DESCRIPTIVAS\")\n",
    "print(\"=\" * 50)\n",
    "display(df.describe(include='all'))\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"VALORES √öNICOS POR COLUMNA\")\n",
    "print(\"=\" * 50)\n",
    "for col in df.columns:\n",
    "    unicos = df[col].nunique()\n",
    "    total = len(df)\n",
    "    porcentaje = (unicos / total) * 100\n",
    "    print(f\"{col:20} | {unicos:6,} √∫nicos ({porcentaje:5.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. M√âTRICAS DE CALIDAD DE DATOS\n",
    "\n",
    "### Funci√≥n para Calcular M√©tricas de Calidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcular_metricas_calidad(df):\n",
    "    \"\"\"\n",
    "    Calcula m√©tricas detalladas de calidad de datos\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    DataFrame: M√©tricas de calidad por columna\n",
    "    \"\"\"\n",
    "    metricas = {}\n",
    "    \n",
    "    for col in df.columns:\n",
    "        valores_nulos = df[col].isnull().sum()\n",
    "        porcentaje_nulos = (valores_nulos / len(df)) * 100\n",
    "        valores_unicos = df[col].nunique()\n",
    "        \n",
    "        # Detectar valores duplicados\n",
    "        duplicados = df[col].duplicated().sum() if df[col].dtype == 'object' else 0\n",
    "        \n",
    "        metricas[col] = {\n",
    "            'valores_nulos': valores_nulos,\n",
    "            'porcentaje_nulos': round(porcentaje_nulos, 2),\n",
    "            'valores_unicos': valores_unicos,\n",
    "            'duplicados': duplicados,\n",
    "            'tipo_datos': str(df[col].dtype),\n",
    "            'valores_nulos_criticos': 'S√ç' if porcentaje_nulos > 50 else 'NO'\n",
    "        }\n",
    "    \n",
    "    return pd.DataFrame(metricas).T\n",
    "\n",
    "# CALCULAR Y MOSTRAR M√âTRICAS\n",
    "print(\"=\" * 60)\n",
    "print(\"M√âTRICAS DE CALIDAD DE DATOS\")\n",
    "print(\"=\" * 60)\n",
    "metricas = calcular_metricas_calidad(df)\n",
    "display(metricas)\n",
    "\n",
    "# Resumen de problemas cr√≠ticos\n",
    "problemas_criticos = metricas[metricas['valores_nulos_criticos'] == 'S√ç']\n",
    "if len(problemas_criticos) > 0:\n",
    "    print(\"\\nCOLUMNAS CON PROBLEMAS CR√çTICOS (>50% nulos):\")\n",
    "    for col in problemas_criticos.index:\n",
    "        print(f\"   - {col}: {problemas_criticos.loc[col, 'porcentaje_nulos']}% valores nulos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. VISUALIZACI√ìN DE PROBLEMAS DE CALIDAD\n",
    "\n",
    "### Mapa de Valores Nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizaci√≥n mejorada de valores nulos\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "fig.suptitle('An√°lisis de Calidad de Datos', fontsize=16, fontweight='bold')\n",
    "\n",
    "# 1. Mapa de calor de valores nulos\n",
    "ax1 = axes[0, 0]\n",
    "sns.heatmap(df.isnull(), cbar=True, cmap=\"RdYlBu_r\", ax=ax1)\n",
    "ax1.set_title(\"üó∫Ô∏è Mapa de Valores Nulos\")\n",
    "ax1.set_xlabel(\"Columnas\")\n",
    "ax1.set_ylabel(\"Filas\")\n",
    "\n",
    "# 2. Barplot de valores nulos por columna\n",
    "ax2 = axes[0, 1]\n",
    "nulos_por_col = df.isnull().sum().sort_values(ascending=False)\n",
    "nulos_por_col = nulos_por_col[nulos_por_col > 0]  # Solo columnas con nulos\n",
    "\n",
    "if len(nulos_por_col) > 0:\n",
    "    nulos_por_col.plot(kind='bar', ax=ax2, color='coral')\n",
    "    ax2.set_title(\"Valores Nulos por Columna\")\n",
    "    ax2.set_ylabel(\"Cantidad de Valores Nulos\")\n",
    "    ax2.tick_params(axis='x', rotation=45)\n",
    "else:\n",
    "    ax2.text(0.5, 0.5, \"No hay valores nulos\", ha='center', va='center', transform=ax2.transAxes)\n",
    "    ax2.set_title(\"Valores Nulos por Columna\")\n",
    "\n",
    "# 3. Distribuci√≥n de tipos de datos\n",
    "ax3 = axes[1, 0]\n",
    "tipos_datos = df.dtypes.value_counts()\n",
    "tipos_datos.plot(kind='pie', autopct='%1.1f%%', ax=ax3)\n",
    "ax3.set_title(\"Distribuci√≥n de Tipos de Datos\")\n",
    "ax3.set_ylabel(\"\")\n",
    "\n",
    "# 4. Histograma de valores √∫nicos\n",
    "ax4 = axes[1, 1]\n",
    "valores_unicos = df.nunique()\n",
    "valores_unicos.hist(bins=20, ax=ax4, color='skyblue', alpha=0.7)\n",
    "ax4.set_title(\"Distribuci√≥n de Valores √önicos\")\n",
    "ax4.set_xlabel(\"Cantidad de Valores √önicos\")\n",
    "ax4.set_ylabel(\"Frecuencia\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Estad√≠sticas generales\n",
    "print(f\"\\nRESUMEN DE CALIDAD:\")\n",
    "print(f\"   ‚Ä¢ Total de valores nulos: {df.isnull().sum().sum():,}\")\n",
    "print(f\"   ‚Ä¢ Porcentaje de datos completos: {((df.size - df.isnull().sum().sum()) / df.size * 100):.1f}%\")\n",
    "print(f\"   ‚Ä¢ Filas completamente llenas: {df.dropna().shape[0]:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. VALIDACI√ìN DE REGLAS DE NEGOCIO\n",
    "\n",
    "### Detecci√≥n de Inconsistencias y Errores L√≥gicos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validar_reglas_negocio(df):\n",
    "    \"\"\"\n",
    "    Valida reglas espec√≠ficas del dominio de ventas\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict: Diccionario con errores encontrados\n",
    "    \"\"\"\n",
    "    errores = {\n",
    "        'fechas_invalidas': 0,\n",
    "        'discrepancias_sales_amount': 0,\n",
    "        'valores_negativos': 0,\n",
    "        'precios_cero': 0,\n",
    "        'cantidades_negativas': 0,\n",
    "        'detalles': []\n",
    "    }\n",
    "    \n",
    "    # 1. Validar fechas l√≥gicas (shipping date >= order date)\n",
    "    fechas_invalidas = df[(df['shippeddate'] < df['orderdate']) & df['shippeddate'].notnull()]\n",
    "    errores['fechas_invalidas'] = len(fechas_invalidas)\n",
    "    if len(fechas_invalidas) > 0:\n",
    "        errores['detalles'].append(f\"üö® {len(fechas_invalidas)} pedidos con fecha de env√≠o antes que fecha de orden\")\n",
    "    \n",
    "    # 2. Validar coherencia en sales_amount vs quantity * price\n",
    "    if 'sales_amount' in df.columns and 'quantityordered' in df.columns and 'priceeach' in df.columns:\n",
    "        calculado = df['quantityordered'] * df['priceeach']\n",
    "        diferencia = abs(df['sales_amount'] - calculado)\n",
    "        discrepancias = diferencia[diferencia > 0.01].count()  # Tolerancia de 1 centavo\n",
    "        errores['discrepancias_sales_amount'] = discrepancias\n",
    "        if discrepancias > 0:\n",
    "            errores['detalles'].append(f\"üö® {discrepancias} pedidos con discrepancias en sales_amount\")\n",
    "    \n",
    "    # 3. Validar valores negativos\n",
    "    numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "    for col in numeric_cols:\n",
    "        negativos = (df[col] < 0).sum()\n",
    "        if negativos > 0:\n",
    "            if 'price' in col.lower():\n",
    "                errores['precios_cero'] += negativos\n",
    "            elif 'quantity' in col.lower():\n",
    "                errores['cantidades_negativas'] += negativos\n",
    "            else:\n",
    "                errores['valores_negativos'] += negativos\n",
    "    \n",
    "    # 4. Validar precios cero\n",
    "    precios_cero = (df['priceeach'] == 0).sum()\n",
    "    errores['precios_cero'] = precios_cero\n",
    "    if precios_cero > 0:\n",
    "        errores['detalles'].append(f\"üö® {precios_cero} productos con precio $0\")\n",
    "    \n",
    "    return errores\n",
    "\n",
    "# EJECUTAR VALIDACIONES\n",
    "print(\"=\" * 60)\n",
    "print(\"VALIDACI√ìN DE REGLAS DE NEGOCIO\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "errores = validar_reglas_negocio(df)\n",
    "\n",
    "if errores['detalles']:\n",
    "    print(\"PROBLEMAS ENCONTRADOS:\")\n",
    "    for detalle in errores['detalles']:\n",
    "        print(f\"   {detalle}\")\n",
    "else:\n",
    "    print(\"No se encontraron problemas cr√≠ticos en las validaciones\")\n",
    "\n",
    "print(f\"\\nRESUMEN DE ERRORES:\")\n",
    "for tipo, cantidad in errores.items():\n",
    "    if tipo != 'detalles' and cantidad > 0:\n",
    "        print(f\"   ‚Ä¢ {tipo.replace('_', ' ').title()}: {cantidad}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. DETECCI√ìN INTELIGENTE DE OUTLIERS\n",
    "\n",
    "### An√°lisis de Valores At√≠picos usando M√©todo IQR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detectar_outliers_iqr(df, columnas=None):\n",
    "    \"\"\"\n",
    "    Detecci√≥n de outliers usando m√©todo IQR (Rango Intercuart√≠lico)\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : DataFrame\n",
    "    columnas : list, optional\n",
    "        Columnas espec√≠ficas a analizar. Si None, usa todas las num√©ricas.\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    DataFrame: Informaci√≥n detallada de outliers por columna\n",
    "    \"\"\"\n",
    "    if columnas is None:\n",
    "        columnas = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    \n",
    "    outliers_info = {}\n",
    "    \n",
    "    for col in columnas:\n",
    "        # Remover valores nulos para c√°lculos\n",
    "        datos = df[col].dropna()\n",
    "        \n",
    "        Q1 = datos.quantile(0.25)\n",
    "        Q3 = datos.quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        \n",
    "        limite_inferior = Q1 - 1.5 * IQR\n",
    "        limite_superior = Q3 + 1.5 * IQR\n",
    "        \n",
    "        outliers = df[(df[col] < limite_inferior) | (df[col] > limite_superior)]\n",
    "        \n",
    "        outliers_info[col] = {\n",
    "            'outliers_count': len(outliers),\n",
    "            'porcentaje_outliers': (len(outliers) / len(df)) * 100,\n",
    "            'Q1': round(Q1, 2),\n",
    "            'Q3': round(Q3, 2),\n",
    "            'IQR': round(IQR, 2),\n",
    "            'limite_inferior': round(limite_inferior, 2),\n",
    "            'limite_superior': round(limite_superior, 2),\n",
    "            'minimo_normal': round(datos.min(), 2),\n",
    "            'maximo_normal': round(datos.max(), 2)\n",
    "        }\n",
    "    \n",
    "    return pd.DataFrame(outliers_info).T\n",
    "\n",
    "# DETECTAR OUTLIERS\n",
    "numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "outliers_info = detectar_outliers_iqr(df, numeric_cols)\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"AN√ÅLISIS DE OUTLIERS (M√âTODO IQR)\")\n",
    "print(\"=\" * 70)\n",
    "display(outliers_info)\n",
    "\n",
    "# Visualizaci√≥n de outliers\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "fig.suptitle('üìä An√°lisis de Outliers', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Boxplots para columnas num√©ricas principales\n",
    "colores = ['lightblue', 'lightgreen', 'lightcoral', 'lightyellow']\n",
    "for i, col in enumerate(numeric_cols[:4]):\n",
    "    if i < 4:\n",
    "        ax = axes[i//2, i%2]\n",
    "        # CORRECCI√ìN: Usar seaborn en lugar de pandas boxplot\n",
    "        sns.boxplot(y=df[col], ax=ax, color=colores[i])\n",
    "        ax.set_title(f\"Boxplot - {col}\")\n",
    "        ax.set_ylabel(col)\n",
    "        \n",
    "        # A√±adir informaci√≥n de outliers\n",
    "        if col in outliers_info.index:\n",
    "            outliers_count = outliers_info.loc[col, 'outliers_count']\n",
    "            porcentaje = outliers_info.loc[col, 'porcentaje_outliers']\n",
    "            ax.text(0.02, 0.98, f'Outliers: {outliers_count} ({porcentaje:.1f}%)', \n",
    "                   transform=ax.transAxes, va='top', \n",
    "                   bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Resumen de outliers por columna\n",
    "print(f\"\\nRESUMEN DE OUTLIERS:\")\n",
    "outliers_criticos = outliers_info[outliers_info['porcentaje_outliers'] > 5]\n",
    "if len(outliers_criticos) > 0:\n",
    "    print(\"‚ö†Ô∏è  Columnas con muchos outliers (>5%):\")\n",
    "    for col in outliers_criticos.index:\n",
    "        print(f\"   ‚Ä¢ {col}: {outliers_criticos.loc[col, 'outliers_count']} outliers ({outliers_criticos.loc[col, 'porcentaje_outliers']:.1f}%)\")\n",
    "else:\n",
    "    print(\"No hay columnas con exceso de outliers (>5%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. FUNCI√ìN PRINCIPAL DE LIMPIEZA\n",
    "\n",
    "### Limpieza Modular y Configurable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def limpiar_datos(df, config_outliers=None, config_nulos=None):\n",
    "    \"\"\"\n",
    "    Funci√≥n principal para limpieza de datos con configuraci√≥n\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : DataFrame\n",
    "        DataFrame con datos a limpiar\n",
    "    config_outliers : dict, optional\n",
    "        Configuraci√≥n para eliminaci√≥n de outliers\n",
    "        Ejemplo: {'quantityordered': 'iqr', 'priceeach': 'iqr'}\n",
    "    config_nulos : dict, optional\n",
    "        Configuraci√≥n para rellenar valores nulos\n",
    "        Ejemplo: {'sales_amount': 'mediana', 'comments': 'texto'}\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    tuple: (df_limpio, reporte_limpieza)\n",
    "    \"\"\"\n",
    "    # Crear copia para trabajar\n",
    "    df_clean = df.copy()\n",
    "    reporte = {\n",
    "        'filas_iniciales': len(df),\n",
    "        'filas_eliminadas': 0,\n",
    "        'valores_rellenados': {},\n",
    "        'transformaciones': [],\n",
    "        'configuracion_outliers': config_outliers or {},\n",
    "        'configuracion_nulos': config_nulos or {}\n",
    "    }\n",
    "    \n",
    "    print(\"INICIANDO PROCESO DE LIMPIEZA...\")\n",
    "    print(f\"Datos iniciales: {len(df_clean):,} filas\")\n",
    "    \n",
    "    # 1. ELIMINAR DUPLICADOS EXACTOS\n",
    "    duplicados_antes = df_clean.duplicated().sum()\n",
    "    if duplicados_antes > 0:\n",
    "        df_clean.drop_duplicates(inplace=True)\n",
    "        reporte['filas_eliminadas'] += duplicados_antes\n",
    "        reporte['transformaciones'].append(f\"Eliminados {duplicados_antes} duplicados exactos\")\n",
    "        print(f\" Duplicados eliminados: {duplicados_antes}\")\n",
    "    \n",
    "    # 2. MANEJAR OUTLIERS\n",
    "    if config_outliers:\n",
    "        print(f\"üîß Procesando outliers en: {list(config_outliers.keys())}\")\n",
    "        for col, metodo in config_outliers.items():\n",
    "            if metodo == 'iqr' and col in df_clean.columns:\n",
    "                # Usar m√©todo IQR\n",
    "                Q1 = df_clean[col].quantile(0.25)\n",
    "                Q3 = df_clean[col].quantile(0.75)\n",
    "                IQR = Q3 - Q1\n",
    "                limite_inf = Q1 - 1.5 * IQR\n",
    "                limite_sup = Q3 + 1.5 * IQR\n",
    "                \n",
    "                # Contar outliers antes de eliminar\n",
    "                outliers_count = ((df_clean[col] < limite_inf) | \n",
    "                                (df_clean[col] > limite_sup)).sum()\n",
    "                \n",
    "                # Eliminar outliers\n",
    "                df_clean = df_clean[(df_clean[col] >= limite_inf) & \n",
    "                                  (df_clean[col] <= limite_sup)]\n",
    "                \n",
    "                reporte['filas_eliminadas'] += outliers_count\n",
    "                reporte['transformaciones'].append(\n",
    "                    f\"Eliminados {outliers_count} outliers de {col} (m√©todo IQR)\"\n",
    "                )\n",
    "                print(f\"   ‚Ä¢ {col}: {outliers_count} outliers eliminados\")\n",
    "    \n",
    "    # 3. MANEJAR VALORES NULOS\n",
    "    if config_nulos:\n",
    "        print(f\"üîß Rellenando valores nulos en: {list(config_nulos.keys())}\")\n",
    "        for col, metodo in config_nulos.items():\n",
    "            if col in df_clean.columns:\n",
    "                nulos_antes = df_clean[col].isnull().sum()\n",
    "                \n",
    "                if metodo == 'mediana':\n",
    "                    valor = df_clean[col].median()\n",
    "                    df_clean[col].fillna(valor, inplace=True)\n",
    "                elif metodo == 'media':\n",
    "                    valor = df_clean[col].mean()\n",
    "                    df_clean[col].fillna(valor, inplace=True)\n",
    "                elif metodo == 'moda':\n",
    "                    valor = df_clean[col].mode().iloc[0]\n",
    "                    df_clean[col].fillna(valor, inplace=True)\n",
    "                elif metodo == 'texto':\n",
    "                    valor = 'Sin informaci√≥n'\n",
    "                    df_clean[col].fillna(valor, inplace=True)\n",
    "                elif metodo == 'forward_fill':\n",
    "                    df_clean[col].fillna(method='ffill', inplace=True)\n",
    "                    valor = 'forward_fill'\n",
    "                \n",
    "                reporte['valores_rellenados'][col] = {\n",
    "                    'metodo': metodo,\n",
    "                    'valor': valor,\n",
    "                    'nulos_rellenados': nulos_antes\n",
    "                }\n",
    "                print(f\"   ‚Ä¢ {col}: {nulos_antes} valores nulos rellenados con {metodo}\")\n",
    "    \n",
    "    # 4. CONVERTIR TIPOS DE DATOS\n",
    "    # Convertir fechas a datetime\n",
    "    date_cols = ['orderdate', 'shippeddate', 'requireddate']\n",
    "    for col in date_cols:\n",
    "        if col in df_clean.columns and df_clean[col].dtype != 'datetime64[ns]':\n",
    "            df_clean[col] = pd.to_datetime(df_clean[col], errors='coerce')\n",
    "            reporte['transformaciones'].append(f\"Convertida columna {col} a datetime\")\n",
    "    \n",
    "    reporte['filas_finales'] = len(df_clean)\n",
    "    reporte['reduccion_porcentaje'] = ((reporte['filas_iniciales'] - reporte['filas_finales']) / \n",
    "                                      reporte['filas_iniciales']) * 100\n",
    "    \n",
    "    print(f\"LIMPIEZA COMPLETADA:\")\n",
    "    print(f\"    Filas finales: {len(df_clean):,}\")\n",
    "    print(f\"    Filas eliminadas: {reporte['filas_eliminadas']:,}\")\n",
    "    print(f\"    Reducci√≥n: {reporte['reduccion_porcentaje']:.1f}%\")\n",
    "    \n",
    "    return df_clean, reporte\n",
    "\n",
    "# CONFIGURACI√ìN DE LIMPIEZA\n",
    "print(\"=\" * 60)\n",
    "print(\"‚öôÔ∏è CONFIGURACI√ìN DE LIMPIEZA\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Configuraci√≥n para outliers\n",
    "config_outliers = {\n",
    "    'quantityordered': 'iqr',\n",
    "    'priceeach': 'iqr'\n",
    "}\n",
    "\n",
    "# Configuraci√≥n para valores nulos\n",
    "config_nulos = {\n",
    "    'sales_amount': 'mediana',\n",
    "    'comments': 'texto'\n",
    "}\n",
    "\n",
    "print(\"üîß Configuraci√≥n de outliers:\")\n",
    "for col, metodo in config_outliers.items():\n",
    "    print(f\"   ‚Ä¢ {col}: m√©todo {metodo.upper()}\")\n",
    "\n",
    "print(\"\\nüîß Configuraci√≥n de valores nulos:\")\n",
    "for col, metodo in config_nulos.items():\n",
    "    print(f\"   ‚Ä¢ {col}: m√©todo {metodo}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EJECUTAR LIMPIEZA\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"EJECUTANDO LIMPIEZA DE DATOS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "df_final, reporte_limpieza = limpiar_datos(df, config_outliers, config_nulos)\n",
    "\n",
    "# MOSTRAR REPORTE DETALLADO\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"REPORTE DETALLADO DE LIMPIEZA\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"ESTAD√çSTICAS GENERALES:\")\n",
    "for key, value in reporte_limpieza.items():\n",
    "    if key not in ['valores_rellenados', 'transformaciones', 'configuracion_outliers', 'configuracion_nulos']:\n",
    "        if key.endswith('_porcentaje'):\n",
    "            print(f\"   ‚Ä¢ {key.replace('_', ' ').title()}: {value:.2f}%\")\n",
    "        else:\n",
    "            print(f\"   ‚Ä¢ {key.replace('_', ' ').title()}: {value:,}\")\n",
    "\n",
    "print(\"\\nTRANSFORMACIONES APLICADAS:\")\n",
    "for i, transformacion in enumerate(reporte_limpieza['transformaciones'], 1):\n",
    "    print(f\"   {i}. {transformacion}\")\n",
    "\n",
    "print(\"\\nVALORES RELLENADOS:\")\n",
    "for col, info in reporte_limpieza['valores_rellenados'].items():\n",
    "    print(f\"   ‚Ä¢ {col}:\")\n",
    "    print(f\"     - M√©todo: {info['metodo']}\")\n",
    "    print(f\"     - Valor: {info['valor']}\")\n",
    "    print(f\"     - Nulos rellenados: {info['nulos_rellenados']}\")\n",
    "\n",
    "print(\"\\nDATOS ANTES VS DESPU√âS:\")\n",
    "print(f\"   ‚Ä¢ Valores nulos iniciales: {df.isnull().sum().sum():,}\")\n",
    "print(f\"   ‚Ä¢ Valores nulos finales: {df_final.isnull().sum().sum():,}\")\n",
    "print(f\"   ‚Ä¢ Mejora en completitud: {((df.size - df.isnull().sum().sum()) / df.size * 100):.1f}% ‚Üí {((df_final.size - df_final.isnull().sum().sum()) / df_final.size * 100):.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. DASHBOARD DE COMPARACI√ìN\n",
    "\n",
    "### Visualizaci√≥n Antes vs Despu√©s de la Limpieza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crear_dashboard_calidad(df_original, df_limpio, reporte):\n",
    "    \"\"\"\n",
    "    Crear dashboard de comparaci√≥n antes/despu√©s de la limpieza\n",
    "    \"\"\"\n",
    "    fig = plt.figure(figsize=(20, 16))\n",
    "    gs = fig.add_gridspec(4, 3, hspace=0.4, wspace=0.3)\n",
    "    \n",
    "    fig.suptitle('Dashboard de Calidad - Antes vs Despu√©s de la Limpieza', \n",
    "                fontsize=20, fontweight='bold', y=0.98)\n",
    "    \n",
    "    # 1. Comparaci√≥n de valores nulos (gr√°fico de barras)\n",
    "    ax1 = fig.add_subplot(gs[0, :2])\n",
    "    nulos_antes = df_original.isnull().sum()\n",
    "    nulos_despues = df_limpio.isnull().sum()\n",
    "    \n",
    "    # Solo mostrar columnas con diferencias\n",
    "    diff_cols = nulos_antes[nulos_antes != nulos_despues]\n",
    "    if len(diff_cols) > 0:\n",
    "        x = np.arange(len(diff_cols))\n",
    "        width = 0.35\n",
    "        \n",
    "        ax1.bar(x - width/2, nulos_antes[diff_cols.index], width, \n",
    "               label='Antes', alpha=0.8, color='coral')\n",
    "        ax1.bar(x + width/2, nulos_despues[diff_cols.index], width, \n",
    "               label='Despu√©s', alpha=0.8, color='lightblue')\n",
    "        \n",
    "        ax1.set_title('Comparaci√≥n de Valores Nulos', fontweight='bold')\n",
    "        ax1.set_xlabel('Columnas')\n",
    "        ax1.set_ylabel('Cantidad de Valores Nulos')\n",
    "        ax1.set_xticks(x)\n",
    "        ax1.set_xticklabels(diff_cols.index, rotation=45, ha='right')\n",
    "        ax1.legend()\n",
    "    else:\n",
    "        ax1.text(0.5, 0.5, 'No hay diferencias en valores nulos', \n",
    "                ha='center', va='center', transform=ax1.transAxes, fontsize=14)\n",
    "        ax1.set_title('Comparaci√≥n de Valores Nulos', fontweight='bold')\n",
    "    \n",
    "    # 2. M√©tricas principales\n",
    "    ax2 = fig.add_subplot(gs[0, 2])\n",
    "    ax2.axis('off')\n",
    "    \n",
    "    metricas_texto = f\"\"\"\n",
    "    M√âTRICAS PRINCIPALES\n",
    "\n",
    "    Datos Iniciales:\n",
    "    ‚Ä¢ Filas: {reporte['filas_iniciales']:,}\n",
    "    ‚Ä¢ Columnas: {df_original.shape[1]}\n",
    "    ‚Ä¢ Valores nulos: {df_original.isnull().sum().sum():,}\n",
    "\n",
    "    Datos Finales:\n",
    "    ‚Ä¢ Filas: {reporte['filas_finales']:,}\n",
    "    ‚Ä¢ Columnas: {df_limpio.shape[1]}\n",
    "    ‚Ä¢ Valores nulos: {df_limpio.isnull().sum().sum():,}\n",
    "\n",
    "    Transformaciones:\n",
    "    ‚Ä¢ Filas eliminadas: {reporte['filas_eliminadas']:,}\n",
    "    ‚Ä¢ Reducci√≥n: {reporte['reduccion_porcentaje']:.1f}%\n",
    "    ‚Ä¢ Mejora completitud: {((df.size - df.isnull().sum().sum()) / df.size * 100):.1f}% ‚Üí {((df_limpio.size - df_limpio.isnull().sum().sum()) / df_limpio.size * 100):.1f}%\n",
    "    \"\"\"\n",
    "    \n",
    "    ax2.text(0.05, 0.95, metricas_texto, transform=ax2.transAxes, \n",
    "            fontsize=11, verticalalignment='top', fontfamily='monospace',\n",
    "            bbox=dict(boxstyle='round,pad=0.5', facecolor='lightgray', alpha=0.8))\n",
    "    \n",
    "    # 3. Distribuci√≥n de sales_amount antes\n",
    "    ax3 = fig.add_subplot(gs[1, 0])\n",
    "    if 'sales_amount' in df_original.columns:\n",
    "        df_original['sales_amount'].hist(bins=50, ax=ax3, alpha=0.7, color='coral')\n",
    "        ax3.set_title('Sales Amount - Antes', fontweight='bold')\n",
    "        ax3.set_xlabel('Sales Amount')\n",
    "        ax3.set_ylabel('Frecuencia')\n",
    "    \n",
    "    # 4. Distribuci√≥n de sales_amount despu√©s\n",
    "    ax4 = fig.add_subplot(gs[1, 1])\n",
    "    if 'sales_amount' in df_limpio.columns:\n",
    "        df_limpio['sales_amount'].hist(bins=50, ax=ax4, alpha=0.7, color='lightblue')\n",
    "        ax4.set_title('Sales Amount - Despu√©s', fontweight='bold')\n",
    "        ax4.set_xlabel('Sales Amount')\n",
    "        ax4.set_ylabel('Frecuencia')\n",
    "    \n",
    "    # 5. Boxplot comparativo\n",
    "    ax5 = fig.add_subplot(gs[1, 2])\n",
    "    if 'sales_amount' in df_original.columns and 'sales_amount' in df_limpio.columns:\n",
    "        data_boxplot = [df_original['sales_amount'].dropna(), \n",
    "                       df_limpio['sales_amount'].dropna()]\n",
    "        ax5.boxplot(data_boxplot, labels=['Antes', 'Despu√©s'])\n",
    "        ax5.set_title('Sales Amount - Comparaci√≥n', fontweight='bold')\n",
    "        ax5.set_ylabel('Sales Amount')\n",
    "    \n",
    "    # 6. Timeline de fechas (si existe)\n",
    "    ax6 = fig.add_subplot(gs[2, :])\n",
    "    if 'orderdate' in df_original.columns:\n",
    "        # CORRECCI√ìN: Convertir a datetime primero y manejar errores\n",
    "        try:\n",
    "            # Convertir a datetime si no lo est√°\n",
    "            if not pd.api.types.is_datetime64_any_dtype(df_original['orderdate']):\n",
    "                fecha_col_antes = pd.to_datetime(df_original['orderdate'], errors='coerce')\n",
    "            else:\n",
    "                fecha_col_antes = df_original['orderdate']\n",
    "            \n",
    "            if not pd.api.types.is_datetime64_any_dtype(df_limpio['orderdate']):\n",
    "                fecha_col_despues = pd.to_datetime(df_limpio['orderdate'], errors='coerce')\n",
    "            else:\n",
    "                fecha_col_despues = df_limpio['orderdate']\n",
    "            \n",
    "            # Agrupar por mes para visualizaci√≥n\n",
    "            fecha_antes = fecha_col_antes.groupby(fecha_col_antes.dt.to_period('M')).size()\n",
    "            fecha_despues = fecha_col_despues.groupby(fecha_col_despues.dt.to_period('M')).size()\n",
    "            \n",
    "            ax6.plot(fecha_antes.index.astype(str), fecha_antes.values, \n",
    "                    marker='o', label='Antes', linewidth=2, color='coral')\n",
    "            ax6.plot(fecha_despues.index.astype(str), fecha_despues.values, \n",
    "                    marker='s', label='Despu√©s', linewidth=2, color='lightblue')\n",
    "            \n",
    "            ax6.set_title('Evoluci√≥n Temporal de Pedidos', fontweight='bold')\n",
    "            ax6.set_xlabel('Mes')\n",
    "            ax6.set_ylabel('Cantidad de Pedidos')\n",
    "            ax6.legend()\n",
    "            ax6.tick_params(axis='x', rotation=45)\n",
    "            \n",
    "        except Exception as e:\n",
    "            # Si hay error, mostrar mensaje alternativo\n",
    "            ax6.text(0.5, 0.5, f'‚ö†Ô∏è Error en datos temporales\\n{e}', \n",
    "                    ha='center', va='center', transform=ax6.transAxes, fontsize=12)\n",
    "            ax6.set_title('Evoluci√≥n Temporal de Pedidos', fontweight='bold')\n",
    "    else:\n",
    "        ax6.text(0.5, 0.5, '‚ÑπÔ∏è No hay columna orderdate', \n",
    "                ha='center', va='center', transform=ax6.transAxes, fontsize=12)\n",
    "        ax6.set_title('Evoluci√≥n Temporal de Pedidos', fontweight='bold')\n",
    "            \n",
    "    # 7. Transformaciones aplicadas\n",
    "    ax7 = fig.add_subplot(gs[3, :2])\n",
    "    transformaciones = reporte['transformaciones']\n",
    "    if transformaciones:\n",
    "        y_pos = np.arange(len(transformaciones))\n",
    "        ax7.barh(y_pos, [1]*len(transformaciones), color='lightgreen', alpha=0.7)\n",
    "        ax7.set_yticks(y_pos)\n",
    "        ax7.set_yticklabels([f\"{i+1}. {t[:50]}...\" if len(t) > 50 else f\"{i+1}. {t}\" \n",
    "                            for i, t in enumerate(transformaciones)])\n",
    "        ax7.set_xlabel('Progreso')\n",
    "        ax7.set_title('Transformaciones Aplicadas', fontweight='bold')\n",
    "        ax7.set_xlim(0, 1)\n",
    "    \n",
    "    # 8. Resumen final\n",
    "    ax8 = fig.add_subplot(gs[3, 2])\n",
    "    ax8.axis('off')\n",
    "    \n",
    "    # Calcular mejoras\n",
    "    mejora_completitud = ((df.size - df.isnull().sum().sum()) / df.size * 100)\n",
    "    mejora_completitud_final = ((df_limpio.size - df_limpio.isnull().sum().sum()) / df_limpio.size * 100)\n",
    "    \n",
    "    resumen_texto = f\"\"\"\n",
    "    RESUMEN FINAL\n",
    "\n",
    "    Objetivo Cumplido:\n",
    "    ‚Ä¢ Datos limpios y validados\n",
    "    ‚Ä¢ Outliers identificados y tratados\n",
    "    ‚Ä¢ Valores nulos manejados\n",
    "    ‚Ä¢ Reglas de negocio validadas\n",
    "\n",
    "    Mejoras Logradas:\n",
    "    ‚Ä¢ Completitud: {mejora_completitud:.1f}% ‚Üí {mejora_completitud_final:.1f}%\n",
    "    ‚Ä¢ Reducci√≥n de datos: {reporte['reduccion_porcentaje']:.1f}%\n",
    "    ‚Ä¢ Calidad mejorada significativamente\n",
    "\n",
    "    Proceso Reproducible:\n",
    "    ‚Ä¢ Configuraci√≥n documentada\n",
    "    ‚Ä¢ Reporte detallado\n",
    "    ‚Ä¢ C√≥digo reutilizable\n",
    "    \"\"\"\n",
    "    \n",
    "    ax8.text(0.05, 0.95, resumen_texto, transform=ax8.transAxes, \n",
    "            fontsize=10, verticalalignment='top',\n",
    "            bbox=dict(boxstyle='round,pad=0.5', facecolor='lightgreen', alpha=0.3))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# CREAR DASHBOARD\n",
    "print(\"=\" * 70)\n",
    "print(\"CREANDO DASHBOARD DE COMPARACI√ìN\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "crear_dashboard_calidad(df, df_final, reporte_limpieza)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. EXPORTACI√ìN Y REPORTES\n",
    "\n",
    "### Guardar Datos Limpios y Documentaci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertir_tipos_pandas(obj):\n",
    "    \"\"\"\n",
    "    Convierte tipos de pandas/numpy no serializables a tipos nativos de Python\n",
    "    para garantizar compatibilidad con JSON\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    from datetime import datetime\n",
    "    \n",
    "    if isinstance(obj, (int, np.integer, pd.Int64Dtype)):\n",
    "        return int(obj)\n",
    "    elif isinstance(obj, (float, np.floating, np.float64, pd.Float64Dtype)):\n",
    "        return float(obj)\n",
    "    elif isinstance(obj, (np.bool_, bool)):\n",
    "        return bool(obj)\n",
    "    elif isinstance(obj, pd.Timestamp):\n",
    "        return obj.isoformat() if pd.notnull(obj) else None\n",
    "    elif isinstance(obj, datetime):\n",
    "        return obj.isoformat() if obj is not None else None\n",
    "    elif isinstance(obj, pd.Series):\n",
    "        return obj.apply(convertir_tipos_pandas).tolist()\n",
    "    elif isinstance(obj, np.ndarray):\n",
    "        return obj.tolist()\n",
    "    elif isinstance(obj, dict):\n",
    "        return {key: convertir_tipos_pandas(value) for key, value in obj.items()}\n",
    "    elif isinstance(obj, list):\n",
    "        return [convertir_tipos_pandas(item) for item in obj]\n",
    "    elif isinstance(obj, tuple):\n",
    "        return tuple(convertir_tipos_pandas(item) for item in obj)\n",
    "    elif pd.isnull(obj):\n",
    "        return None\n",
    "    else:\n",
    "        return obj\n",
    "\n",
    "def exportar_resultados(df_limpio, reporte, output_dir='./output/'):\n",
    "    \"\"\"\n",
    "    Exportar datos limpios y reportes de calidad\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df_limpio : DataFrame\n",
    "        DataFrame limpio para exportar\n",
    "    reporte : dict\n",
    "        Reporte de limpieza generado\n",
    "    output_dir : str\n",
    "        Directorio de salida\n",
    "    \"\"\"\n",
    "    import os\n",
    "    import json\n",
    "    from datetime import datetime\n",
    "    \n",
    "    # Crear directorio si no existe\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Generar timestamp\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    \n",
    "    # 1. Exportar datos limpios\n",
    "    archivo_datos = f\"{output_dir}ventas_limpias_{timestamp}.csv\"\n",
    "    df_limpio.to_csv(archivo_datos, index=False)\n",
    "    print(f\"Datos limpios guardados: {archivo_datos}\")\n",
    "    \n",
    "    # 2. Exportar reporte de limpieza en JSON\n",
    "    archivo_reporte = f\"{output_dir}reporte_calidad_{timestamp}.json\"\n",
    "    \n",
    "    # Convertir reporte usando la funci√≥n robusta\n",
    "    reporte_json = convertir_tipos_pandas(reporte)\n",
    "    \n",
    "    with open(archivo_reporte, 'w', encoding='utf-8') as f:\n",
    "        json.dump(reporte_json, f, indent=2, ensure_ascii=False)\n",
    "    print(f\"Reporte JSON guardado: {archivo_reporte}\")\n",
    "    \n",
    "    # 3. Exportar diccionario de datos\n",
    "    diccionario_datos = {\n",
    "        'nombre_dataset': 'ventas_limpias',\n",
    "        'fecha_limpieza': datetime.now().isoformat(),\n",
    "        'version': '1.0',\n",
    "        'filas': len(df_limpio),\n",
    "        'columnas': list(df_limpio.columns),\n",
    "        'dtypes': {col: str(dtype) for col, dtype in df_limpio.dtypes.items()},\n",
    "        'memoria_mb': round(df_limpio.memory_usage(deep=True).sum() / 1024**2, 2),\n",
    "        'estadisticas_descriptivas': convertir_tipos_pandas(df_limpio.describe().to_dict()),\n",
    "        'valores_unicos': {col: int(df_limpio[col].nunique()) for col in df_limpio.columns},\n",
    "        'valores_nulos_finales': convertir_tipos_pandas(df_limpio.isnull().sum().to_dict()),\n",
    "        'configuracion_limpieza': {\n",
    "            'outliers': reporte.get('configuracion_outliers', {}),\n",
    "            'nulos': reporte.get('configuracion_nulos', {})\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    archivo_diccionario = f\"{output_dir}datos_dict_{timestamp}.json\"\n",
    "    with open(archivo_diccionario, 'w', encoding='utf-8') as f:\n",
    "        json.dump(diccionario_datos, f, indent=2, ensure_ascii=False)\n",
    "    print(f\"Diccionario de datos guardado: {archivo_diccionario}\")\n",
    "    \n",
    "    # 4. Exportar reporte legible en texto\n",
    "    archivo_reporte_txt = f\"{output_dir}reporte_calidad_{timestamp}.txt\"\n",
    "    with open(archivo_reporte_txt, 'w', encoding='utf-8') as f:\n",
    "        f.write(\"=\"*80 + \"\\n\")\n",
    "        f.write(\"REPORTE DE LIMPIEZA DE DATOS\\n\")\n",
    "        f.write(\"=\"*80 + \"\\n\\n\")\n",
    "        \n",
    "        f.write(f\"Fecha de procesamiento: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
    "        f.write(f\"Dataset: ventas_limpias\\n\")\n",
    "        f.write(f\"Versi√≥n: 1.0\\n\\n\")\n",
    "        \n",
    "        f.write(\"ESTAD√çSTICAS GENERALES:\\n\")\n",
    "        f.write(\"-\"*40 + \"\\n\")\n",
    "        for key, value in reporte.items():\n",
    "            if key not in ['valores_rellenados', 'transformaciones', 'configuracion_outliers', 'configuracion_nulos']:\n",
    "                if key.endswith('_porcentaje'):\n",
    "                    f.write(f\"{key.replace('_', ' ').title()}: {float(value):.2f}%\\n\")\n",
    "                else:\n",
    "                    f.write(f\"{key.replace('_', ' ').title()}: {int(value):,}\\n\")\n",
    "        \n",
    "        f.write(\"\\nTRANSFORMACIONES APLICADAS:\\n\")\n",
    "        f.write(\"-\"*40 + \"\\n\")\n",
    "        for i, transformacion in enumerate(reporte['transformaciones'], 1):\n",
    "            f.write(f\"{i}. {transformacion}\\n\")\n",
    "        \n",
    "        f.write(\"\\nVALORES RELLENADOS:\\n\")\n",
    "        f.write(\"-\"*40 + \"\\n\")\n",
    "        for col, info in reporte['valores_rellenados'].items():\n",
    "            f.write(f\"{col}:\\n\")\n",
    "            f.write(f\"  - M√©todo: {info['metodo']}\\n\")\n",
    "            f.write(f\"  - Valor: {info['valor']}\\n\")\n",
    "            f.write(f\"  - Nulos rellenados: {info['nulos_rellenados']}\\n\")\n",
    "        \n",
    "        f.write(\"\\nCONFIGURACI√ìN UTILIZADA:\\n\")\n",
    "        f.write(\"-\"*40 + \"\\n\")\n",
    "        f.write(\"Outliers: \" + str(reporte.get('configuracion_outliers', {})) + \"\\n\")\n",
    "        f.write(\"Valores nulos: \" + str(reporte.get('configuracion_nulos', {})) + \"\\n\")\n",
    "    \n",
    "    print(f\"Reporte textual guardado: {archivo_reporte_txt}\")\n",
    "    \n",
    "    return {\n",
    "        'datos': archivo_datos,\n",
    "        'reporte_json': archivo_reporte,\n",
    "        'diccionario': archivo_diccionario,\n",
    "        'reporte_txt': archivo_reporte_txt\n",
    "    }\n",
    "\n",
    "# EJECUTAR EXPORTACI√ìN\n",
    "print(\"=\" * 60)\n",
    "print(\"EXPORTANDO RESULTADOS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "archivos_exportados = exportar_resultados(df_final, reporte_limpieza)\n",
    "\n",
    "print(f\"\\nEXPORTACI√ìN COMPLETADA:\")\n",
    "print(f\"   Datos limpios: {archivos_exportados['datos']}\")\n",
    "print(f\"   Reporte JSON: {archivos_exportados['reporte_json']}\")\n",
    "print(f\"   Diccionario: {archivos_exportados['diccionario']}\")\n",
    "print(f\"   Reporte textual: {archivos_exportados['reporte_txt']}\")\n",
    "\n",
    "print(f\"\\nPR√ìXIMOS PASOS SUGERIDOS:\")\n",
    "print(f\"   ‚Ä¢ Analizar outliers identificados\")\n",
    "print(f\"   ‚Ä¢ Revisar valores nulos restantes\")\n",
    "print(f\"   ‚Ä¢ Validar reglas de negocio aplicadas\")\n",
    "print(f\"   ‚Ä¢ Documentar hallazgos en reporte final\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. RESUMEN FINAL Y VALIDACIONES\n",
    "\n",
    "### Verificaci√≥n Final de la Calidad de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VALIDACI√ìN FINAL\n",
    "print(\"=\" * 70)\n",
    "print(\"üéØ VALIDACI√ìN FINAL Y RESUMEN EJECUTIVO\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Verificar calidad final\n",
    "def validacion_final(df_original, df_limpio, reporte):\n",
    "    \"\"\"Validaci√≥n final de la calidad de datos\"\"\"\n",
    "    \n",
    "    validaciones = {\n",
    "        'sin_duplicados_exactos': not df_limpio.duplicated().any(),\n",
    "        'tipos_datos_correctos': True,\n",
    "        'valores_nulos_esperados': True,\n",
    "        'rango_datos_coherente': True,\n",
    "        'outliers_tratados': True\n",
    "    }\n",
    "    \n",
    "    # Verificar tipos de datos\n",
    "    date_cols = ['orderdate', 'shippeddate', 'requireddate']\n",
    "    for col in date_cols:\n",
    "        if col in df_limpio.columns:\n",
    "            if df_limpio[col].dtype != 'datetime64[ns]':\n",
    "                validaciones['tipos_datos_correctos'] = False\n",
    "    \n",
    "    # Verificar que valores nulos esperados fueron manejados\n",
    "    valores_nulos_esperados = ['sales_amount', 'comments']\n",
    "    for col in valores_nulos_esperados:\n",
    "        if col in df_limpio.columns:\n",
    "            if col in reporte['configuracion_nulos']:\n",
    "                if df_limpio[col].isnull().sum() > 0:\n",
    "                    validaciones['valores_nulos_esperados'] = False\n",
    "    \n",
    "    return validaciones\n",
    "\n",
    "# Ejecutar validaci√≥n\n",
    "validaciones = validacion_final(df, df_final, reporte_limpieza)\n",
    "\n",
    "print(\"RESULTADOS DE VALIDACI√ìN:\")\n",
    "for validacion, resultado in validaciones.items():\n",
    "    status = \"PAS√ì\" if resultado else \"‚ùå FALL√ì\"\n",
    "    print(f\"   ‚Ä¢ {validacion.replace('_', ' ').title()}: {status}\")\n",
    "\n",
    "# Resumen ejecutivo\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"RESUMEN EJECUTIVO\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "mejora_completitud = ((df.size - df.isnull().sum().sum()) / df.size * 100)\n",
    "mejora_completitud_final = ((df_final.size - df_final.isnull().sum().sum()) / df_final.size * 100)\n",
    "\n",
    "resumen = f\"\"\"\n",
    "OBJETIVOS ALCANZADOS:\n",
    "   - Dataset limpio y validado\n",
    "   - Outliers identificados y tratados\n",
    "   - Valores nulos manejados apropiadamente\n",
    "   - Reglas de negocio verificadas\n",
    "   - Proceso documentado y reproducible\n",
    "\n",
    "M√âTRICAS DE CALIDAD:\n",
    "   ‚Ä¢ Completitud: {mejora_completitud:.1f}% ‚Üí {mejora_completitud_final:.1f}%\n",
    "   ‚Ä¢ Reducci√≥n de datos: {reporte_limpieza['reduccion_porcentaje']:.1f}%\n",
    "   ‚Ä¢ Transformaciones aplicadas: {len(reporte_limpieza['transformaciones'])}\n",
    "   ‚Ä¢ Valores rellenados: {len(reporte_limpieza['valores_rellenados'])}\n",
    "\n",
    "ARCHIVOS GENERADOS:\n",
    "   ‚Ä¢ Datos limpios listos para an√°lisis\n",
    "   ‚Ä¢ Reportes detallados de calidad\n",
    "   ‚Ä¢ Documentaci√≥n completa del proceso\n",
    "   ‚Ä¢ Configuraciones reutilizables\n",
    "\n",
    "PR√ìXIMOS PASOS SUGERIDOS:\n",
    "   1. An√°lisis exploratorio de datos (EDA)\n",
    "   2. Modelado predictivo o anal√≠tico\n",
    "   3. Dashboards y visualizaciones\n",
    "   4. Automatizaci√≥n del proceso de limpieza\n",
    "\n",
    "BENEFICIOS LOGRADOS:\n",
    "   ‚Ä¢ Datos confiables para toma de decisiones\n",
    "   ‚Ä¢ Proceso reproducible y escalable\n",
    "   ‚Ä¢ Documentaci√≥n completa para auditor√≠as\n",
    "   ‚Ä¢ Base s√≥lida para an√°lisis avanzados\n",
    "\"\"\"\n",
    "\n",
    "print(resumen)\n",
    "\n",
    "# Mostrar primeras filas del dataset final\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"üëÄ MUESTRA DEL DATASET FINAL LIMPIO\")\n",
    "print(\"=\" * 70)\n",
    "display(df_final.head(10))\n",
    "\n",
    "print(f\"\\nPROCESO DE LIMPIEZA COMPLETADO EXITOSAMENTE\")\n",
    "print(f\"Dataset final: {df_final.shape[0]:,} filas x {df_final.shape[1]} columnas\")\n",
    "print(f\"Calidad mejorada de {mejora_completitud:.1f}% a {mejora_completitud_final:.1f}%\")\n",
    "print(f\"Archivos guardados en: './output/'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
