{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2bd58377",
   "metadata": {},
   "source": [
    "# Uso de Dask para Procesar Datos Masivos\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88fee800",
   "metadata": {},
   "source": [
    "Dask es una biblioteca paralela y distribuida en Python que permite escalar cálculos comunes (como los de `pandas`, `numpy` o `scikit-learn`) a conjuntos de datos más grandes de los que pueden manejar estas herramientas directamente.\n",
    "\n",
    "### Ventajas:\n",
    "- Sintaxis similar a `pandas` y `numpy`\n",
    "- Manejo eficiente de datos que no entran en memoria\n",
    "- Paralelismo automático\n",
    "- Integración con múltiples fuentes de datos\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee74bb98",
   "metadata": {},
   "source": [
    "## Instalación\n",
    "\n",
    "Si aún no tienes instalado `dask`, ejecuta:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac3f930",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install dask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb6c9aae",
   "metadata": {},
   "source": [
    "También puedes instalarlo junto con otras dependencias útiles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa54ea3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install \"dask[dataframe]\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4136e394",
   "metadata": {},
   "source": [
    "## Importar Librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f47a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import dask.dataframe as dd\n",
    "import pandas as pd\n",
    "import numpy as n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4710a34a",
   "metadata": {},
   "source": [
    "## Cargar un dataset grande con Dask\n",
    "\n",
    "Supongamos que tienes un archivo CSV muy grande. Con `dask.dataframe.read_csv()` puedes cargarlo sin necesidad de que entre todo en memoria:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f046dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "big_csv=\"https://github.com/ricardoahumada/Python_for_Data_Science/raw/refs/heads/master/data/2008.zip\"\n",
    "small_csv=\"https://github.com/ricardoahumada/Python_for_Data_Science/raw/refs/heads/master/data/2008_small.zip\"\n",
    "very_small_csv = 'https://github.com/ricardoahumada/data-for-auditors/raw/refs/heads/main/4.%20An%C3%A1lisis%20Masivo%20de%20Datos/Optimizacion/data/2008_very_small.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76eab8ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para acceder a archivos en URLs, Dask necesitas instalar las librerías adicionales:\n",
    "# !pip install requests aiohttp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d417b905",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = dd.read_csv(big_csv,dtype={'CancellationCode': 'object'})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad7412ea",
   "metadata": {},
   "source": [
    "\n",
    "> ✅ Nota: `dask.dataframe` tiene casi las mismas funciones que `pandas`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5467816",
   "metadata": {},
   "source": [
    "## Verificar estructura del DataFrame\n",
    "\n",
    "Como Dask trabaja de forma perezosa (*lazy evaluation*), no se ejecutan operaciones hasta que llamas a `.compute()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef373fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()  # Muestra las primeras filas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db3dc092",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns  # Nombres de columnas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d2e71e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes   # Tipos de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "763a2520",
   "metadata": {},
   "source": [
    "## Operaciones básicas con Dask\n",
    "\n",
    "### Filtrar datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "247c93f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = df[df['ArrDelay'] > 3]\n",
    "filtered_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5073d5f",
   "metadata": {},
   "source": [
    "\n",
    "### Seleccionar columnas\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a4a39e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = df[['Year', 'Month', 'DayofMonth', 'DayOfWeek']]\n",
    "subset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad75a37e",
   "metadata": {},
   "source": [
    "\n",
    "### Agregaciones\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cfaf5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "promedio_DepDelay = df['DepDelay'].mean().compute()\n",
    "print(f\"Promedio de DepDelay: {promedio_DepDelay:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72397c0d",
   "metadata": {},
   "source": [
    "\n",
    "### Agrupamiento\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28635933",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = df.groupby('Origin')['DepDelay'].mean().compute()\n",
    "print(grouped)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10824e94",
   "metadata": {},
   "source": [
    "## Optimización de tipos de datos\n",
    "\n",
    "Puedes convertir columnas a tipos más ligeros, como `category`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea63928",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6bac210",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Origin'] = df['Origin'].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9776018",
   "metadata": {},
   "source": [
    "\n",
    "O también puedes especificar los tipos al cargar:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69954472",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtypes = {\n",
    "    'AirTime': np.int32,\n",
    "    'Origin': str,\n",
    "    'Year': np.int8,\n",
    "    'ArrDelay': np.float32,\n",
    "    'CancellationCode': 'category'\n",
    "}\n",
    "\n",
    "df = dd.read_csv(very_small_csv, dtype=dtypes)\n",
    "\n",
    "df.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34b42e69",
   "metadata": {},
   "source": [
    "## Eliminar columnas innecesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e455b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = df.drop(['Unnamed: 0','FlightNum','CancellationCode'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce5d83a6",
   "metadata": {},
   "source": [
    "## Particionar los datos\n",
    "\n",
    "Dask divide automáticamente los datos en particiones. Puedes ver cuántas hay:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5231c2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.npartitions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c0216d",
   "metadata": {},
   "source": [
    "\n",
    "Cambiar número de particiones (útil para optimizar rendimiento):\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e33b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.repartition(npartitions=10)\n",
    "print(df.npartitions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ccacaa2",
   "metadata": {},
   "source": [
    "## Guardar resultados procesados\n",
    "\n",
    "Después de aplicar transformaciones, puedes guardar el resultado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21cebe2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"./output/resultado_procesado.csv\", compute=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0357347f",
   "metadata": {},
   "source": [
    "\n",
    "> Esto guardará archivos por partición: `resultado_procesado_0.csv`, `resultado_procesado_1.csv`, etc.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4325a7db",
   "metadata": {},
   "source": [
    "## Comparación con Pandas\n",
    "\n",
    "Para ver la diferencia, carga el mismo archivo con `pandas`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d19d1c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    df_pandas = pd.read_csv(big_csv)\n",
    "    print(\"Cargado con pandas\")\n",
    "except MemoryError:\n",
    "    print(\"Archivo demasiado grande para pandas\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26cf694b",
   "metadata": {},
   "source": [
    "\n",
    "Con `dask`:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cfe02f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dask = dd.read_csv(big_csv)\n",
    "print(\"Cargado con dask\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fadc3f61",
   "metadata": {},
   "source": [
    "## Visualización básica\n",
    "\n",
    "Puedes usar `matplotlib` o `seaborn` con `.compute()` para graficar:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90429f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dd.read_csv(very_small_csv,dtype={'CancellationCode': 'object'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0884964",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df.groupby('Origin')['DepDelay'].mean().compute().plot(kind='bar')\n",
    "plt.title(\"DepDelay promedio por origen\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c58261",
   "metadata": {},
   "source": [
    "## Resumen de diferencias clave: `dask.dataframe` vs `pandas`\n",
    "\n",
    "| Característica | `pandas` | `dask.dataframe` |\n",
    "|----------------|----------|------------------|\n",
    "| Tamaño máximo de datos | Menor que la RAM disponible | Mayor que la RAM |\n",
    "| Evaluación | Inmediata | Lazy (solo con `.compute()`) |\n",
    "| Velocidad | Rápido para datasets pequeños | Más lento por operación, pero escalable |\n",
    "| Paralelismo | No | Sí, usa múltiples núcleos |\n",
    "| API | Idéntica | Similar, pero no totalmente compatible |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f710d3e2",
   "metadata": {},
   "source": [
    "## Más información\n",
    "\n",
    "- [Documentación oficial de Dask](https://docs.dask.org/en/stable/)\n",
    "- [Dask + Pandas Tutorial](https://tutorial.dask.org/01x_dask_collections.html)\n",
    "- [Dask ML Docs](https://ml.dask.org/)\n",
    "- [Comparación Dask vs Spark](https://coiled.io/blog/dask-vs-spark/)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
