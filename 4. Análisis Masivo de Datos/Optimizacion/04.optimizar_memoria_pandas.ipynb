{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a6bdff9",
   "metadata": {},
   "source": [
    "\n",
    "# **Optimizaci√≥n de Memoria con Pandas**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a250d22",
   "metadata": {},
   "source": [
    "Cuando trabajamos con grandes vol√∫menes de datos (cientos de miles o millones de filas), la biblioteca `pandas` puede consumir mucha memoria RAM si no se usan t√©cnicas adecuadas.\n",
    "\n",
    "Para ello deberemos:\n",
    "- Verificar y optimizar el uso de memoria\n",
    "- Usar tipos de datos m√°s eficientes (`dtypes`)\n",
    "- Cargar solo los datos necesarios\n",
    "- Procesar archivos por bloques (chunks)\n",
    "- Eliminar columnas innecesarias\n",
    "- Convertir tipos de forma autom√°tica"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51cb29b3",
   "metadata": {},
   "source": [
    "## Importar Librer√≠as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd461a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from time import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a864cbc5",
   "metadata": {},
   "source": [
    "## Configurar el entorno de visualizaci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "setup_matplotlib",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_matplotlib_for_plotting():\n",
    "    \"\"\"\n",
    "    Setup matplotlib and seaborn for plotting with proper configuration.\n",
    "    Call this function before creating any plots to ensure proper rendering.\n",
    "    \"\"\"\n",
    "    # Configure matplotlib for non-interactive mode\n",
    "    plt.switch_backend(\"Agg\")\n",
    "\n",
    "    # Set chart style\n",
    "    plt.style.use(\"seaborn-v0_8\")\n",
    "    sns.set_palette(\"husl\")\n",
    "\n",
    "    # Configure platform-appropriate fonts for cross-platform compatibility\n",
    "    plt.rcParams[\"font.sans-serif\"] = [\"Noto Sans CJK SC\", \"WenQuanYi Zen Hei\", \"PingFang SC\", \"Arial Unicode MS\", \"Hiragino Sans GB\"]\n",
    "    plt.rcParams[\"axes.unicode_minus\"] = False\n",
    "\n",
    "setup_matplotlib_for_plotting()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc4ff92",
   "metadata": {},
   "source": [
    "## Funciones auxiliares para m√©tricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "metric_functions",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_memory_usage(df, label=\"\"):\n",
    "    \"\"\"Obtiene el uso de memoria de un DataFrame\"\"\"\n",
    "    memory_mb = df.memory_usage(deep=True).sum() / 1024**2\n",
    "    if label:\n",
    "        print(f\"{label}: {memory_mb:.2f} MB\")\n",
    "    return memory_mb\n",
    "\n",
    "def compare_memory_optimization(original_df, optimized_df, step_name):\n",
    "    \"\"\"Compara memoria entre DataFrames original y optimizado\"\"\"\n",
    "    original_memory = get_memory_usage(original_df, f\"Original ({step_name})\")\n",
    "    optimized_memory = get_memory_usage(optimized_df, f\"Optimizado ({step_name})\")\n",
    "    \n",
    "    savings_mb = original_memory - optimized_memory\n",
    "    savings_percent = (savings_mb / original_memory) * 100\n",
    "    \n",
    "    print(f\"Ahorro: {savings_mb:.2f} MB ({savings_percent:.1f}%)\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    return {\n",
    "        'step': step_name,\n",
    "        'original_mb': original_memory,\n",
    "        'optimized_mb': optimized_memory,\n",
    "        'savings_mb': savings_mb,\n",
    "        'savings_percent': savings_percent\n",
    "    }\n",
    "\n",
    "def show_dtype_info(df, step_name=\"\"):\n",
    "    \"\"\"Muestra informaci√≥n detallada de tipos de datos\"\"\"\n",
    "    print(f\"\\nTipos de datos {step_name}:\")\n",
    "    dtype_summary = df.dtypes.value_counts()\n",
    "    print(dtype_summary)\n",
    "    \n",
    "    # Mostrar tipos por columna\n",
    "    print(\"\\nDetalle por columna:\")\n",
    "    for col in df.columns:\n",
    "        dtype = df[col].dtype\n",
    "        unique_vals = df[col].nunique()\n",
    "        memory_col = df[col].memory_usage(deep=True) / 1024**2\n",
    "        print(f\"  {col:20} | {str(dtype):10} | {unique_vals:>8} √∫nicos | {memory_col:>6.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "load_dataset",
   "metadata": {},
   "source": [
    "## Cargar un dataset grande"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2607db91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# URLs de datasets\n",
    "big_csv=\"https://github.com/ricardoahumada/Python_for_Data_Science/raw/refs/heads/master/data/2008.zip\"\n",
    "small_csv=\"https://github.com/ricardoahumada/Python_for_Data_Science/raw/refs/heads/master/data/2008_small.zip\"\n",
    "very_small_csv = 'https://github.com/ricardoahumada/data-for-auditors/raw/refs/heads/main/4.%20An%C3%A1lisis%20Masivo%20de%20Datos/Optimizacion/data/2008_very_small.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74009003",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar dataset original\n",
    "print(\"Cargando dataset original...\")\n",
    "start_time = time()\n",
    "df_original = pd.read_csv(small_csv)\n",
    "load_time = time() - start_time\n",
    "\n",
    "print(f\"Dataset cargado en {load_time:.2f} segundos\")\n",
    "print(f\"Dimensiones: {df_original.shape[0]:,} filas √ó {df_original.shape[1]} columnas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f596617f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Informaci√≥n general del dataset\n",
    "print(\"üìã Informaci√≥n del Dataset:\")\n",
    "df_original.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baseline_memory",
   "metadata": {},
   "source": [
    "## An√°lisis inicial de memoria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baseline_memory_check",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear copia para trabajar\n",
    "df = df_original.copy()\n",
    "\n",
    "# An√°lisis inicial de memoria\n",
    "print(\"AN√ÅLISIS INICIAL DE MEMORIA\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "baseline_memory = get_memory_usage(df, \"Memoria inicial\")\n",
    "\n",
    "# Mostrar uso por columna\n",
    "print(\"\\nUso de memoria por columna:\")\n",
    "memory_by_column = df.memory_usage(deep=True).sort_values(ascending=False) / 1024**2\n",
    "for col, memory in memory_by_column.head(10).items():\n",
    "    print(f\"  {col:25} | {memory:>8.2f} MB\")\n",
    "\n",
    "# Informaci√≥n de tipos inicial\n",
    "show_dtype_info(df, \"(Inicial)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "optimization_1",
   "metadata": {},
   "source": [
    "## OPTIMIZACI√ìN 1: Cargar solo columnas necesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "select_columns",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrar todas las columnas disponibles\n",
    "print(\"Columnas disponibles en el dataset:\")\n",
    "for i, col in enumerate(df_original.columns, 1):\n",
    "    print(f\"  {i:2d}. {col}\")\n",
    "\n",
    "print(f\"\\nTotal de columnas: {len(df_original.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load_selected_columns",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir columnas m√°s importantes (ejemplo para an√°lisis de vuelos)\n",
    "important_cols = ['Year', 'Month', 'DayofMonth', 'DayOfWeek', 'DepTime',\n",
    "       'CRSDepTime', 'ArrTime', 'CRSArrTime', 'UniqueCarrier', 'ActualElapsedTime', \n",
    "       'CRSElapsedTime', 'AirTime', 'ArrDelay', 'DepDelay', 'Origin', 'Dest', \n",
    "       'Distance', 'Cancelled', 'Diverted', 'CarrierDelay', 'WeatherDelay', \n",
    "       'NASDelay', 'SecurityDelay', 'LateAircraftDelay']\n",
    "\n",
    "# Verificar qu√© columnas existen realmente\n",
    "available_cols = [col for col in important_cols if col in df_original.columns]\n",
    "missing_cols = [col for col in important_cols if col not in df_original.columns]\n",
    "\n",
    "print(f\"Columnas a cargar: {len(available_cols)}\")\n",
    "print(f\"Columnas faltantes: {len(missing_cols)}\")\n",
    "if missing_cols:\n",
    "    print(\"  Faltantes:\", missing_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comparison_step1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparaci√≥n de memoria antes y despu√©s\n",
    "df_step1 = df_original.copy()\n",
    "result_step1 = compare_memory_optimization(\n",
    "    df_step1, \n",
    "    pd.read_csv(small_csv, usecols=available_cols), \n",
    "    \"Selecci√≥n de Columnas\"\n",
    ")\n",
    "\n",
    "# Actualizar DataFrame\n",
    "df = pd.read_csv(small_csv, usecols=available_cols)\n",
    "print(f\"Nuevas dimensiones: {df.shape[0]:,} filas √ó {df.shape[1]} columnas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "optimization_2",
   "metadata": {},
   "source": [
    "## OPTIMIZACI√ìN 2: Optimizaci√≥n manual de tipos de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "manual_optimization",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Optimizaci√≥n manual de tipos de datos\")\n",
    "\n",
    "# Analizar rangos de valores para optimizaci√≥n manual\n",
    "print(\"\\nAn√°lisis de rangos para optimizaci√≥n:\")\n",
    "for col in df.select_dtypes(include=['int64']).columns:\n",
    "    min_val = df[col].min()\n",
    "    max_val = df[col].max()\n",
    "    print(f\"  {col:20} | rango: [{min_val:>6}, {max_val:>6}]\")\n",
    "\n",
    "for col in df.select_dtypes(include=['float64']).columns:\n",
    "    min_val = df[col].min()\n",
    "    max_val = df[col].max()\n",
    "    has_negative = df[col].min() < 0\n",
    "    print(f\"  {col:20} | rango: [{min_val:>8.1f}, {max_val:>8.1f}] | neg: {has_negative}\")\n",
    "\n",
    "print(\"\\nAplicando optimizaciones manuales...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "apply_manual_optimization",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear copia para comparar\n",
    "df_step2_before = df.copy()\n",
    "\n",
    "# Optimizaciones manuales basadas en el an√°lisis\n",
    "optimizations = {}\n",
    "\n",
    "# Optimizar columnas num√©ricas basadas en rangos\n",
    "for col in df.select_dtypes(include=['int64']).columns:\n",
    "    col_min = df[col].min()\n",
    "    col_max = df[col].max()\n",
    "    \n",
    "    if col_min >= 0 and col_max <= 255:\n",
    "        df[col] = df[col].astype(np.uint8)\n",
    "        optimizations[col] = \"uint8\"\n",
    "    elif col_min >= 0 and col_max <= 65535:\n",
    "        df[col] = df[col].astype(np.uint16)\n",
    "        optimizations[col] = \"uint16\"\n",
    "    elif col_min >= -128 and col_max <= 127:\n",
    "        df[col] = df[col].astype(np.int8)\n",
    "        optimizations[col] = \"int8\"\n",
    "    elif col_min >= -32768 and col_max <= 32767:\n",
    "        df[col] = df[col].astype(np.int16)\n",
    "        optimizations[col] = \"int16\"\n",
    "    elif col_min >= -8388608 and col_max <= 8388607:\n",
    "        df[col] = df[col].astype(np.int32)\n",
    "        optimizations[col] = \"int32\"\n",
    "\n",
    "# Optimizar flotantes\n",
    "for col in df.select_dtypes(include=['float64']).columns:\n",
    "    df[col] = pd.to_numeric(df[col], downcast='float')\n",
    "    optimizations[col] = \"float32\"\n",
    "\n",
    "# Convertir strings a categor√≠as si tienen pocos valores √∫nicos\n",
    "for col in df.select_dtypes(include=['object']).columns:\n",
    "    unique_ratio = df[col].nunique() / len(df)\n",
    "    if unique_ratio < 0.5:  # Menos del 50% de valores √∫nicos\n",
    "        df[col] = df[col].astype('category')\n",
    "        optimizations[col] = \"category\"\n",
    "\n",
    "print(\"Optimizaciones aplicadas:\")\n",
    "for col, dtype in optimizations.items():\n",
    "    print(f\"  {col:20} ‚Üí {dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comparison_step2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparaci√≥n despu√©s de optimizaci√≥n manual\n",
    "result_step2 = compare_memory_optimization(\n",
    "    df_step2_before, \n",
    "    df, \n",
    "    \"Optimizaci√≥n Manual\"\n",
    ")\n",
    "\n",
    "# Mostrar cambios en tipos\n",
    "print(\"\\nCambios en tipos de datos:\")\n",
    "for col in df.columns:\n",
    "    if col in optimizations:\n",
    "        print(f\"  {col:20} | {str(df_step2_before[col].dtype):10} ‚Üí {str(df[col].dtype):10}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "optimization_3",
   "metadata": {},
   "source": [
    "## OPTIMIZACI√ìN 3: Funci√≥n autom√°tica de optimizaci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "auto_optimization_function",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_dtypes_advanced(df):\n",
    "    \"\"\"\n",
    "    Funci√≥n avanzada de optimizaci√≥n de tipos de datos\n",
    "    \"\"\"\n",
    "    optimized_df = df.copy()\n",
    "    changes = {}\n",
    "    \n",
    "    # Optimizar n√∫meros flotantes\n",
    "    for col in df.select_dtypes(include=['float64']).columns:\n",
    "        original_dtype = optimized_df[col].dtype\n",
    "        optimized_df[col] = pd.to_numeric(df[col], downcast='float')\n",
    "        new_dtype = optimized_df[col].dtype\n",
    "        if original_dtype != new_dtype:\n",
    "            changes[col] = f\"{original_dtype} ‚Üí {new_dtype}\"\n",
    "    \n",
    "    # Optimizar enteros\n",
    "    for col in df.select_dtypes(include=['int64']).columns:\n",
    "        original_dtype = optimized_df[col].dtype\n",
    "        optimized_df[col] = pd.to_numeric(df[col], downcast='integer')\n",
    "        new_dtype = optimized_df[col].dtype\n",
    "        if original_dtype != new_dtype:\n",
    "            changes[col] = f\"{original_dtype} ‚Üí {new_dtype}\"\n",
    "    \n",
    "    # Convertir objetos a categor√≠as si es apropiado\n",
    "    for col in df.select_dtypes(include=['object']).columns:\n",
    "        # Solo convertir si hay pocos valores √∫nicos relativamente\n",
    "        unique_ratio = df[col].nunique() / len(df)\n",
    "        if unique_ratio < 0.6:  # Umbral ajustable\n",
    "            try:\n",
    "                original_dtype = optimized_df[col].dtype\n",
    "                optimized_df[col] = df[col].astype('category')\n",
    "                new_dtype = optimized_df[col].dtype\n",
    "                if original_dtype != new_dtype:\n",
    "                    changes[col] = f\"{original_dtype} ‚Üí {new_dtype}\"\n",
    "            except:\n",
    "                pass  # Si falla, mantener tipo original\n",
    "    \n",
    "    return optimized_df, changes\n",
    "\n",
    "print(\"Aplicando funci√≥n de optimizaci√≥n autom√°tica...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "apply_auto_optimization",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicar optimizaci√≥n autom√°tica\n",
    "df_step3_before = df.copy()\n",
    "df_optimized, auto_changes = optimize_dtypes_advanced(df)\n",
    "\n",
    "print(\"Cambios autom√°ticos aplicados:\")\n",
    "for col, change in auto_changes.items():\n",
    "    print(f\"  {col:20} | {change}\")\n",
    "\n",
    "# Actualizar DataFrame\n",
    "df = df_optimized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comparison_step3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparaci√≥n despu√©s de optimizaci√≥n autom√°tica\n",
    "result_step3 = compare_memory_optimization(\n",
    "    df_step3_before, \n",
    "    df, \n",
    "    \"Optimizaci√≥n Autom√°tica\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "optimization_4",
   "metadata": {},
   "source": [
    "## OPTIMIZACI√ìN 4: Limpieza de valores nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "analyze_nulls",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analizar valores nulos\n",
    "print(\"üîç An√°lisis de valores nulos:\")\n",
    "null_counts = df.isnull().sum()\n",
    "null_percentages = (null_counts / len(df)) * 100\n",
    "\n",
    "null_info = pd.DataFrame({\n",
    "    'Columna': null_counts.index,\n",
    "    'Valores_Nulos': null_counts.values,\n",
    "    'Porcentaje': null_percentages.values\n",
    "}).sort_values('Valores_Nulos', ascending=False)\n",
    "\n",
    "# Mostrar solo columnas con nulos\n",
    "null_columns = null_info[null_info['Valores_Nulos'] > 0]\n",
    "if len(null_columns) > 0:\n",
    "    print(null_columns.to_string(index=False))\n",
    "else:\n",
    "    print(\"No hay valores nulos en el dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "clean_nulls",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estrategia de limpieza seg√∫n el tipo de datos\n",
    "df_step4_before = df.copy()\n",
    "\n",
    "print(\"\\nüßπ Aplicando limpieza de valores nulos...\")\n",
    "\n",
    "# Para columnas num√©ricas, usar mediana (m√°s robusta que media)\n",
    "numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "for col in numeric_cols:\n",
    "    if df[col].isnull().any():\n",
    "        fill_value = df[col].median()\n",
    "        df[col].fillna(fill_value, inplace=True)\n",
    "        print(f\"  {col:20} | Rellenado con mediana: {fill_value}\")\n",
    "\n",
    "# Para columnas categ√≥ricas, usar moda (valor m√°s frecuente)\n",
    "categorical_cols = df.select_dtypes(include=['category', 'object']).columns\n",
    "for col in categorical_cols:\n",
    "    if df[col].isnull().any():\n",
    "        fill_value = df[col].mode()[0] if len(df[col].mode()) > 0 else 'Desconocido'\n",
    "        df[col].fillna(fill_value, inplace=True)\n",
    "        print(f\"  {col:20} | Rellenado con moda: {fill_value}\")\n",
    "\n",
    "# Verificar que no quedan nulos\n",
    "remaining_nulls = df.isnull().sum().sum()\n",
    "print(f\"\\nValores nulos restantes: {remaining_nulls}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comparison_step4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparaci√≥n despu√©s de limpieza de nulos\n",
    "result_step4 = compare_memory_optimization(\n",
    "    df_step4_before, \n",
    "    df, \n",
    "    \"Limpieza de Nulos\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary_visualization",
   "metadata": {},
   "source": [
    "## RESUMEN DE OPTIMIZACIONES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "create_summary_table",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear tabla resumen de todas las optimizaciones\n",
    "optimization_results = [result_step1, result_step2, result_step3, result_step4]\n",
    "\n",
    "summary_df = pd.DataFrame(optimization_results)\n",
    "print(\"RESUMEN COMPLETO DE OPTIMIZACIONES\")\n",
    "print(\"=\" * 80)\n",
    "print(summary_df.to_string(index=False, float_format='%.2f'))\n",
    "\n",
    "# Calcular ahorros acumulativos\n",
    "total_original = summary_df['original_mb'].iloc[0]\n",
    "total_final = summary_df['optimized_mb'].iloc[-1]\n",
    "total_savings_mb = total_original - total_final\n",
    "total_savings_percent = (total_savings_mb / total_original) * 100\n",
    "\n",
    "print(f\"\\nRESUMEN TOTAL:\")\n",
    "print(f\"   Memoria inicial:     {total_original:>8.2f} MB\")\n",
    "print(f\"   Memoria final:       {total_final:>8.2f} MB\")\n",
    "print(f\"   Ahorro total:        {total_savings_mb:>8.2f} MB\")\n",
    "print(f\"   Porcentaje de ahorro: {total_savings_percent:>7.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "final_info",
   "metadata": {},
   "source": [
    "## Informaci√≥n final del dataset optimizado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "final_info_display",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"INFORMACI√ìN FINAL DEL DATASET OPTIMIZADO\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "df.info()\n",
    "\n",
    "print(f\"\\nTipos de datos finales:\")\n",
    "show_dtype_info(df, \"(Final)\")\n",
    "\n",
    "print(f\"\\nUso de memoria por columna (Top 10):\")\n",
    "final_memory = df.memory_usage(deep=True).sort_values(ascending=False) / 1024**2\n",
    "for col, memory in final_memory.head(10).items():\n",
    "    print(f\"  {col:25} | {memory:>8.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chunks_example",
   "metadata": {},
   "source": [
    "## Ejemplo: Procesamiento por Chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chunk_processing_demo",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_chunk(chunk):\n",
    "    \"\"\"Ejemplo de funci√≥n de procesamiento para chunks\"\"\"\n",
    "    # Operaciones que podr√≠as hacer en cada chunk\n",
    "    stats = {\n",
    "        'filas': len(chunk),\n",
    "        'memoria_mb': chunk.memory_usage(deep=True).sum() / 1024**2,\n",
    "        'columnas': len(chunk.columns)\n",
    "    }\n",
    "    return stats\n",
    "\n",
    "print(\"üì¶ Procesamiento por Chunks - Demostraci√≥n\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "chunk_results = []\n",
    "chunk_size = 50000  # 50,000 filas por chunk\n",
    "\n",
    "print(f\"Procesando en chunks de {chunk_size:,} filas...\")\n",
    "for i, chunk in enumerate(pd.read_csv(small_csv, chunksize=chunk_size), 1):\n",
    "    stats = process_chunk(chunk)\n",
    "    stats['chunk_num'] = i\n",
    "    chunk_results.append(stats)\n",
    "    \n",
    "    print(f\"Chunk {i}: {stats['filas']:,} filas | {stats['memoria_mb']:.2f} MB\")\n",
    "    \n",
    "    # Solo procesar los primeros 3 chunks para la demo\n",
    "    if i >= 3:\n",
    "        break\n",
    "\n",
    "print(f\"\\nProcesados {len(chunk_results)} chunks\")\n",
    "print(f\"Total memoria m√°xima por chunk: {max(r['memoria_mb'] for r in chunk_results):.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "best_practices",
   "metadata": {},
   "source": [
    "## Mejores Pr√°cticas y Recomendaciones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "best_practices_summary",
   "metadata": {},
   "source": [
    "1. **ANALIZA ANTES DE OPTIMIZAR:**\n",
    "- Usa df.info() y df.memory_usage() para identificar problemas\n",
    "- Revisa los rangos de valores para elegir tipos √≥ptimos\n",
    "- Identifica columnas con muchos valores nulos\n",
    "   \n",
    "2. **OPTIMIZA TIPOS DE DATOS:**\n",
    "- int8/int16/int32 para enteros (seg√∫n rango necesario)\n",
    "- float32 para n√∫meros decimales\n",
    "- 'category' para strings con pocos valores √∫nicos\n",
    "- 'datetime64[ns]' para fechas\n",
    "   \n",
    "3. **LIMPIA TUS DATOS:**\n",
    "- Elimina columnas que no uses con df.drop()\n",
    "- Rellena valores nulos apropiadamente\n",
    "- Usa usecols= para cargar solo columnas necesarias\n",
    "   \n",
    "4. **PARA ARCHIVOS MUY GRANDES:**\n",
    "- Usa chunksize en pd.read_csv()\n",
    "- Procesa datos por lotes\n",
    "- Considera usar formatos m√°s eficientes (Parquet, HDF5)\n",
    "   \n",
    "5. **MONITORIZA RENDIMIENTO:**\n",
    "- Mide memoria antes y despu√©s de cada paso\n",
    "- Usa time() para medir tiempo de procesamiento\n",
    "- Documenta el impacto de cada optimizaci√≥n\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "references",
   "metadata": {},
   "source": [
    "## M√°s informaci√≥n:\n",
    "\n",
    "- [Documentaci√≥n oficial de pandas](https://pandas.pydata.org/pandas-docs/stable/)\n",
    "- [Categor√≠as en pandas](https://pandas.pydata.org/docs/user_guide/enhancingperf.html)\n",
    "- [Uso de chunks](https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html)\n",
    "- [Downcasting num√©rico](https://pandas.pydata.org/docs/user_guide/enhancingperf.html#memory-usage)\n",
    "- [Gu√≠a de optimizaci√≥n de memoria](https://pandas.pydata.org/docs/user_guide/scale.html)\n",
    "- [Tipos de datos eficientes](https://pandas.pydata.org/docs/user_guide/enhancingperf.html#memory-usage)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
